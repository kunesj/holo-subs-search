services:
  faster-whisper-server-cuda:
    image: fedirz/faster-whisper-server:latest-cuda
    restart: unless-stopped
    ports:
      - 8000:8000
    volumes:
      - hugging_face_cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              #device_ids: ['0']
              count: all
              capabilities: [gpu]

  faster-whisper-server-cpu:
    image: fedirz/faster-whisper-server:latest-cpu
    restart: unless-stopped
    ports:
      - 8000:8000
    volumes:
      - hugging_face_cache:/root/.cache/huggingface

  pyannote-server-cuda:
    image: local/pyannote-server:latest-cuda
    build:
      context: .
      dockerfile: .docker-pyannote-server/Dockerfile
    pull_policy: never
    restart: unless-stopped
    ports:
      - 8001:8001
    volumes:
      - hugging_face_cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              #device_ids: ['0']
              count: all
              capabilities: [gpu]

  pyannote-server-cpu:
    image: local/pyannote-server:latest-cpu
    build:
      context: .
      dockerfile: .docker-pyannote-server/Dockerfile
      args:
        - TORCH_CPU=1
    pull_policy: never
    restart: unless-stopped
    ports:
      - 8001:8001
    volumes:
      - hugging_face_cache:/root/.cache/huggingface

volumes:
  hugging_face_cache:
