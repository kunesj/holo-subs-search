from __future__ import annotations

import datetime
import logging
import pathlib
from typing import TYPE_CHECKING, Any, Iterator, Self

import srt
from pydantic import BaseModel, ConfigDict, Field

if TYPE_CHECKING:
    import openai.types.audio

_logger = logging.getLogger(__name__)
_config = ConfigDict(
    validate_assignment=True,
    validate_default=True,
    validate_return=True,
    arbitrary_types_allowed=True,
    extra="allow",
)


class TranscriptionSegment(BaseModel):
    model_config = _config

    start: float = Field()
    end: float = Field()
    text: str = Field()
    lang: str = Field()

    @classmethod
    def from_openai_json(cls: type[Self], value: dict[str, Any], lang: str) -> Self:
        """
        https://platform.openai.com/docs/api-reference/audio/verbose-json-object
        {
        'id': 1,
        'seek': 2920,
        'start': 0.0,
        'end': 11.3,
        'text': ' The little tales they tell are false. The door was barred, locked, and bolted as well.',
        'tokens': [50364, 440, 707, 27254, 436, 980, 366, 7908, 13, 440, 2853, 390, 2159, 986, 11, 9376, 11, 293,
          13436, 292, 382, 731, 13, 50929],
        'temperature': 0.0,
        'avg_logprob': -0.2589897227613893,
        'compression_ratio': 1.4886363636363635,
        # IMPORTANT: This is actually garbage and can be very random. Don't use it.
        'no_speech_prob': 0.1307373046875,
        'words': None
        }
        """
        return cls(
            start=value["start"],
            end=value["end"],
            text=value["text"],
            lang=lang,
        )

    @classmethod
    def iter_from_srt(cls: type[Self], source: str | pathlib.Path, lang: str) -> Iterator[Self]:
        """
        Capable of parsing overlapping subtitle lines, like what's generated by YouTube:
        - merges/splits duplicated lines
        - removes some unneeded special characters
        - generated lines might be overlapping
        """
        if isinstance(source, pathlib.Path):
            source = source.read_text()
        elif not isinstance(source, str):
            raise TypeError(source)

        unfinished: list[TranscriptionSegment] = []

        for sub in srt.parse(source):
            sub_start = sub.start.total_seconds()
            sub_end = sub.end.total_seconds()

            # split content into separate lines

            raw_lines = []

            for raw_line in sub.content.splitlines():
                raw_line = raw_line.replace("[\\h__\\h]", "")
                raw_line = " ".join(raw_line.split())
                if raw_line:
                    raw_lines.append(raw_line)

            if not raw_lines:
                continue  # empty subtitle

            # remove finished lines

            while (
                unfinished
                and raw_lines
                and (
                    # does not have same text
                    unfinished[0].text != raw_lines[0]
                    # is not continuation of previous line
                    or unfinished[0].end != sub_start
                )
            ):
                yield unfinished.pop(0)

            # update end time of current lines

            while (
                unfinished
                and raw_lines
                # has the same text
                and unfinished[0].text == raw_lines[0]
                # is continuation of previous line
                and unfinished[0].end == sub_start
            ):
                raw_lines.pop(0)
                unfinished[0].end = sub_end

            # add new lines

            unfinished += [cls(start=sub_start, end=sub_end, text=raw_line, lang=lang) for raw_line in raw_lines]

        for seg in unfinished:
            yield seg


class Transcription(BaseModel):
    model_config = _config

    segments: list[TranscriptionSegment] = Field(default_factory=list)
    params: dict = Field(default_factory=dict, description="Parameters that were used for transcription. Freeform.")

    def get_lang_counts(self) -> dict[str, int]:
        _langs = [x.lang for x in self.segments]
        return {_lang: _langs.count(_lang) for _lang in set(_langs)}

    def get_main_langs(self, *, min_occurrence: float = 0.1) -> set[str]:
        lang_counts = self.get_lang_counts()
        return {_lang for _lang, _count in lang_counts.items() if _count >= (len(self.segments) * min_occurrence)}

    @classmethod
    def from_openai_transcription(cls: type[Self], value: openai.types.audio.Transcription) -> Self:
        """
        https://platform.openai.com/docs/api-reference/audio/verbose-json-object
        """
        return cls(segments=[TranscriptionSegment.from_openai_json(x, lang=value.language) for x in value.segments])

    @classmethod
    def from_srt(cls: type[Self], source: str | pathlib.Path, lang: str) -> Self:
        return cls(segments=list(TranscriptionSegment.iter_from_srt(source, lang=lang)))

    def to_srt(self) -> str:
        return srt.compose(
            [
                srt.Subtitle(
                    index=1,
                    start=datetime.timedelta(seconds=x.start),
                    end=datetime.timedelta(seconds=x.end),
                    content=x.text,
                )
                for x in self.segments
            ],
            reindex=True,
        )
